{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import argparse\nimport networkx as nx\nimport torch\nimport torch.nn as nn\n\n!pip install torch-geometric\nfrom torch_geometric.nn import GCNConv","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T10:35:17.726044Z","iopub.execute_input":"2025-04-09T10:35:17.726402Z","iopub.status.idle":"2025-04-09T10:35:36.935474Z","shell.execute_reply.started":"2025-04-09T10:35:17.726370Z","shell.execute_reply":"2025-04-09T10:35:36.934770Z"}},"outputs":[{"name":"stdout","text":"Collecting torch-geometric\n  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.11.12)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.12.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.67.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.18.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2025.1.31)\nRequirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch-geometric) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torch-geometric) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torch-geometric) (2024.2.0)\nDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch-geometric\nSuccessfully installed torch-geometric-2.6.1\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"TODO:\nImplement teacher network architecture and training along with flags for datasets and teacher model architecture (Chanikya and Nithin)\neg: python3 train_teacher.py --dataset=cora --model=SAGE --epochs-100 --lr=0.01 . Add flags for other hyperparameters if necessary (Chanikya and Nithin)\nOther teacher model architectures - GCN, GAT, APPNP (Chanikya and Nithin + others based on availability)","metadata":{}},{"cell_type":"code","source":"from torch_geometric.datasets import Planetoid\ndataset = Planetoid(root='./Cora', name='Cora')\n\ndata = dataset[0]\nprint(f'Dataset: {dataset}:')\nprint('======================')\nprint(f'Number of graphs: {len(dataset)}')\nprint(f'Number of features: {dataset.num_features}')\nprint(f'Number of classes: {dataset.num_classes}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T10:35:36.936671Z","iopub.execute_input":"2025-04-09T10:35:36.937182Z","iopub.status.idle":"2025-04-09T10:35:39.225270Z","shell.execute_reply.started":"2025-04-09T10:35:36.937148Z","shell.execute_reply":"2025-04-09T10:35:39.223515Z"}},"outputs":[{"name":"stderr","text":"Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\nDownloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\nDownloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\nDownloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\nDownloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\nDownloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\nDownloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\nDownloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\nProcessing...\n","output_type":"stream"},{"name":"stdout","text":"Dataset: Cora():\n======================\nNumber of graphs: 1\nNumber of features: 1433\nNumber of classes: 7\n","output_type":"stream"},{"name":"stderr","text":"Done!\n","output_type":"stream"}],"execution_count":6},{"cell_type":"raw","source":"TODO: \n1. Standardise(lcc)\n2. binarize labels(dealing with multi labels)\n3. for now only worksfor cpf, extenf to ogb","metadata":{}},{"cell_type":"code","source":"# data.edge_index.t()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T10:35:56.151491Z","iopub.execute_input":"2025-04-09T10:35:56.152026Z","iopub.status.idle":"2025-04-09T10:35:56.155578Z","shell.execute_reply.started":"2025-04-09T10:35:56.151996Z","shell.execute_reply":"2025-04-09T10:35:56.154748Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def load_data(dataset):\n    if dataset == \"cora\":\n        dataset = Planetoid(root='./Cora', name='Cora')\n        data = dataset[0]\n        graph_nx = nx.Graph()\n        graph_nx.add_edges_from(data.edge_index.t().tolist())\n\n        # Adding self-loops\n        # graph_nx.add_edges_from((n, n) for n in graph_nx.nodes())\n        \n        # adj_tensor = torch.tensor(nx.to_numpy_array(graph_nx), dtype=torch.float).to('cuda')\n        features = data.x\n        labels = data.y\n\n        train_idx = data.train_mask.nonzero(as_tuple=True)[0]\n        val_idx = data.val_mask.nonzero(as_tuple=True)[0]\n        test_idx = data.test_mask.nonzero(as_tuple=True)[0]\n        \n        return data.edge_index, features, labels, data.train_mask, data.val_mask, data.test_mask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T10:35:56.481928Z","iopub.execute_input":"2025-04-09T10:35:56.482235Z","iopub.status.idle":"2025-04-09T10:35:56.487702Z","shell.execute_reply.started":"2025-04-09T10:35:56.482213Z","shell.execute_reply":"2025-04-09T10:35:56.486914Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"cnt = 0\n140+1000+500\n2708\nfor x in data.val_mask:\n    cnt += (x==True)\nprint(cnt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T10:35:57.797045Z","iopub.execute_input":"2025-04-09T10:35:57.797403Z","iopub.status.idle":"2025-04-09T10:35:57.836105Z","shell.execute_reply.started":"2025-04-09T10:35:57.797372Z","shell.execute_reply":"2025-04-09T10:35:57.835207Z"}},"outputs":[{"name":"stdout","text":"tensor(500)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"GCN => num layers, hidden, input dim, out, dp, activa,  ","metadata":{}},{"cell_type":"code","source":"class GCN(nn.Module):\n    def __init__(\n        self,\n        num_layers,\n        input_dim,\n        hidden_dim,\n        output_dim,\n        dropout_ratio,\n        activation,\n        norm_type=\"none\"\n    ):\n        super().__init__()\n        self.num_layers = num_layers\n        self.norm_type = norm_type\n        self.dropout = nn.Dropout(dropout_ratio)\n        self.activation = activation\n\n        self.layers = nn.ModuleList()\n        self.norms = nn.ModuleList()\n\n        if num_layers == 1:\n            self.layers.append(GCNConv(input_dim, output_dim))\n        else:\n            self.layers.append(GCNConv(input_dim, hidden_dim))\n            if norm_type == \"batch\":\n                self.norms.append(nn.BatchNorm1d(hidden_dim))\n            elif norm_type == \"layer\":\n                self.norms.append(nn.LayerNorm(hidden_dim))\n\n            for _ in range(num_layers - 2):\n                self.layers.append(GCNConv(hidden_dim, hidden_dim))\n                if norm_type == \"batch\":\n                    self.norms.append(nn.BatchNorm1d(hidden_dim))\n                elif norm_type == \"layer\":\n                    self.norms.append(nn.LayerNorm(hidden_dim))\n\n            self.layers.append(GCNConv(hidden_dim, output_dim))\n\n    def forward(self, x, edge_index):\n        h_list = []\n        h = x\n        for l, layer in enumerate(self.layers):\n            h = layer(h, edge_index)\n            if l != self.num_layers - 1:\n                if self.norm_type != \"none\":\n                    h = self.norms[l](h)\n                h = self.activation(h)\n                h = self.dropout(h)\n                h_list.append(h)\n        return h","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T10:54:06.884606Z","iopub.execute_input":"2025-04-09T10:54:06.884942Z","iopub.status.idle":"2025-04-09T10:54:06.892709Z","shell.execute_reply.started":"2025-04-09T10:54:06.884920Z","shell.execute_reply":"2025-04-09T10:54:06.891800Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"def train(model, data, edge_index, labels, train_idx, optimizer, criterion):\n    model.train()\n    optimizer.zero_grad()\n    out = model(data, edge_index)\n    loss = criterion(out[train_idx], labels[train_idx])\n    loss.backward()\n    optimizer.step()\n    return loss.item()\n\n@torch.no_grad()\ndef evaluate(model, data, edge_index, labels, idx):\n    model.eval()\n    out = model(data, edge_index)\n    pred = out[idx].argmax(dim=1)\n    correct = (pred == labels[idx]).sum().item()\n    acc = correct / sum(idx)\n    return acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T10:55:10.936231Z","iopub.execute_input":"2025-04-09T10:55:10.936625Z","iopub.status.idle":"2025-04-09T10:55:10.941872Z","shell.execute_reply.started":"2025-04-09T10:55:10.936593Z","shell.execute_reply":"2025-04-09T10:55:10.941082Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"edge_index, features, labels, train_idx, val_idx, test_idx = load_data(\"cora\")\nmodel = GCN(\n    num_layers=3,\n    input_dim=dataset.num_node_features,\n    hidden_dim=64,\n    output_dim=dataset.num_classes,\n    dropout_ratio=0.8,\n    activation=nn.functional.relu,\n    norm_type=\"batch\"\n)\n# model = GCN1(dataset.num_node_features, 64, dataset.num_classes)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\ncriterion = torch.nn.CrossEntropyLoss()\n\nfor epoch in range(1, 150):\n    loss = train(model, features, edge_index, labels, train_idx, optimizer, criterion)\n    val_acc = evaluate(model, features, edge_index, labels, val_idx)\n    if epoch % 10 == 0 or epoch == 1:\n        test_acc = evaluate(model, features, edge_index, labels, test_idx)\n        print(f\"Epoch {epoch:03d} | Loss: {loss:.4f} | Val Acc: {val_acc:.4f} | Test Acc: {test_acc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:02:11.817111Z","iopub.execute_input":"2025-04-09T11:02:11.817505Z","iopub.status.idle":"2025-04-09T11:02:18.866503Z","shell.execute_reply.started":"2025-04-09T11:02:11.817475Z","shell.execute_reply":"2025-04-09T11:02:18.865446Z"}},"outputs":[{"name":"stdout","text":"Epoch 001 | Loss: 2.2817 | Val Acc: 0.4040 | Test Acc: 0.3970\nEpoch 010 | Loss: 0.7035 | Val Acc: 0.7620 | Test Acc: 0.7750\nEpoch 020 | Loss: 0.3302 | Val Acc: 0.7580 | Test Acc: 0.7720\nEpoch 030 | Loss: 0.1283 | Val Acc: 0.7500 | Test Acc: 0.7770\nEpoch 040 | Loss: 0.1200 | Val Acc: 0.7500 | Test Acc: 0.7720\nEpoch 050 | Loss: 0.0830 | Val Acc: 0.7440 | Test Acc: 0.7710\nEpoch 060 | Loss: 0.0759 | Val Acc: 0.7580 | Test Acc: 0.7800\nEpoch 070 | Loss: 0.0625 | Val Acc: 0.7540 | Test Acc: 0.7770\nEpoch 080 | Loss: 0.0946 | Val Acc: 0.7520 | Test Acc: 0.7830\nEpoch 090 | Loss: 0.0331 | Val Acc: 0.7520 | Test Acc: 0.7740\nEpoch 100 | Loss: 0.0359 | Val Acc: 0.7440 | Test Acc: 0.7650\nEpoch 110 | Loss: 0.0450 | Val Acc: 0.7480 | Test Acc: 0.7640\nEpoch 120 | Loss: 0.0718 | Val Acc: 0.7360 | Test Acc: 0.7670\nEpoch 130 | Loss: 0.0740 | Val Acc: 0.7380 | Test Acc: 0.7620\nEpoch 140 | Loss: 0.0403 | Val Acc: 0.7380 | Test Acc: 0.7670\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model(data.x, data.edge_index)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T10:34:45.801513Z","iopub.status.idle":"2025-04-09T10:34:45.801807Z","shell.execute_reply":"2025-04-09T10:34:45.801706Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Teacher:\n    def __init__(self, args):\n        self.args = args\n        pass\n    def graph_split():\n        pass\n    def train_transductive():\n        pass\n    def train_inductive():\n        pass\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T10:34:45.877203Z","iopub.execute_input":"2025-04-09T10:34:45.877456Z","iopub.status.idle":"2025-04-09T10:34:45.881064Z","shell.execute_reply.started":"2025-04-09T10:34:45.877435Z","shell.execute_reply":"2025-04-09T10:34:45.880425Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def main():\n    parser = argparse.ArgumentParser(description=\"Teacher implementation\")\n    parser.add_argument('--num_runs', type=int, default=1, help='Number of runs')\n    parser.add_argument('--setting', type=str, choices=['trans', 'ind'], required=True, help='Setting type: trans or ind')\n    parser.add_argument('--data_path', type=str, required=True, help='Path to the dataset')\n    parser.add_argument('--model_name', type=str, default='SAGE', help='Name of the model(SAGE, GCN, GAT, APPNP)')\n    parser.add_argument('--num_layers', type=int, default=2, help='Number of layers in the model')\n    parser.add_argument('--hidden_dim', type=int, default=128, help='Hidden dimension size')\n    parser.add_argument('--drop_out', type=float, default=0, help='Dropout rate')\n    parser.add_argument('--batch_sz', type=int, default=512, help='Batch size')\n    parser.add_argument('--learning_rate', type=float, default=0.01, help='Learning rate')\n    parser.add_argument('--output_path', type=str, default='./output', help='Path to save output')\n    \n    args = parser.parse_args()\n\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T10:34:45.882088Z","iopub.execute_input":"2025-04-09T10:34:45.882306Z","iopub.status.idle":"2025-04-09T10:34:45.903383Z","shell.execute_reply.started":"2025-04-09T10:34:45.882287Z","shell.execute_reply":"2025-04-09T10:34:45.902618Z"}},"outputs":[],"execution_count":3}]}